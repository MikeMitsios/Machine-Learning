{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zw7wzWrmiaX3",
    "outputId": "d5691f0b-d261-4d90-a8af-4acd2802d6e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user-sl/Documents/metaptyxiako/Machine_Learning/Exc3\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WKQ0s2VtTyC",
    "outputId": "27015f9e-01a6-455a-dfc1-79e73bafd729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-mnist in /home/user-sl/.local/lib/python3.8/site-packages (0.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Ub_sYyShWA4",
    "outputId": "a004b02f-903d-4853-8910-86a00da7248f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mnist import MNIST\n",
    "\n",
    "# In order to work unzip the MNIST files and put them under the same directory, i.e. /MNIST_dataset\n",
    "Location = '/home/user-sl/Documents/metaptyxiako/Machine_Learning/Exc3/MNIST_dataset'\n",
    "\n",
    "mndata = MNIST(Location)\n",
    "\n",
    "images_train, labels_train = mndata.load_training()\n",
    "# or\n",
    "images_test, labels_test = mndata.load_testing()\n",
    "\n",
    "print(np.array(images_train).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFeiaO_B0ThB",
    "outputId": "be2886a3-74f8-4b8c-feb3-5ee96a151ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215686\n",
      " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
      " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1372549  0.94509804\n",
      " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      " 0.58823529 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.58039216\n",
      " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058824\n",
      " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
      " 0.31372549 0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333333 0.99215686\n",
      " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "#using the MaxAbsScaler to normalize our data to [0,1]\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "X_train_maxabs = max_abs_scaler.fit_transform(images_train)\n",
    "X_test_maxabs = max_abs_scaler.transform(images_test)\n",
    "\n",
    "print(labels_train[0])\n",
    "print(X_train_maxabs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpijfZw403G1",
    "outputId": "b32a52f1-7951-44ac-ee59-77d556750cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.97647059 -0.85882353 -0.85882353 -0.85882353\n",
      " -0.01176471  0.06666667  0.37254902 -0.79607843  0.30196078  1.\n",
      "  0.9372549  -0.00392157 -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.76470588 -0.71764706 -0.2627451   0.20784314\n",
      "  0.33333333  0.98431373  0.98431373  0.98431373  0.98431373  0.98431373\n",
      "  0.76470588  0.34901961  0.98431373  0.89803922  0.52941176 -0.49803922\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -0.61568627\n",
      "  0.86666667  0.98431373  0.98431373  0.98431373  0.98431373  0.98431373\n",
      "  0.98431373  0.98431373  0.98431373  0.96862745 -0.27058824 -0.35686275\n",
      " -0.35686275 -0.56078431 -0.69411765 -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -0.85882353  0.71764706  0.98431373\n",
      "  0.98431373  0.98431373  0.98431373  0.98431373  0.55294118  0.42745098\n",
      "  0.9372549   0.89019608 -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.37254902  0.22352941 -0.16078431  0.98431373\n",
      "  0.98431373  0.60784314 -0.91372549 -1.         -0.6627451   0.20784314\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -0.89019608 -0.99215686  0.20784314  0.98431373 -0.29411765\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.          0.09019608  0.98431373  0.49019608 -0.98431373 -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -0.91372549\n",
      "  0.49019608  0.98431373 -0.45098039 -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -0.7254902   0.89019608\n",
      "  0.76470588  0.25490196 -0.15294118 -0.99215686 -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -0.36470588  0.88235294  0.98431373\n",
      "  0.98431373 -0.06666667 -0.80392157 -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.64705882  0.45882353  0.98431373  0.98431373\n",
      "  0.17647059 -0.78823529 -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -0.8745098  -0.27058824  0.97647059  0.98431373  0.46666667\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.          0.95294118  0.98431373  0.95294118 -0.49803922 -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.63921569  0.01960784  0.43529412  0.98431373\n",
      "  0.98431373  0.62352941 -0.98431373 -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -0.69411765  0.16078431\n",
      "  0.79607843  0.98431373  0.98431373  0.98431373  0.96078431  0.42745098\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -0.81176471 -0.10588235  0.73333333  0.98431373  0.98431373  0.98431373\n",
      "  0.98431373  0.57647059 -0.38823529 -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.81960784 -0.48235294  0.67058824  0.98431373\n",
      "  0.98431373  0.98431373  0.98431373  0.55294118 -0.36470588 -0.98431373\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -0.85882353  0.34117647\n",
      "  0.71764706  0.98431373  0.98431373  0.98431373  0.98431373  0.52941176\n",
      " -0.37254902 -0.92941176 -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -0.56862745  0.34901961  0.77254902  0.98431373  0.98431373  0.98431373\n",
      "  0.98431373  0.91372549  0.04313725 -0.91372549 -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.          0.06666667  0.98431373\n",
      "  0.98431373  0.98431373  0.6627451   0.05882353  0.03529412 -0.8745098\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#using MinMaxScaler to normalize our data to [-1,1]\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "X_train_minmax = min_max_scaler.fit_transform(images_train)\n",
    "X_test_minmax = min_max_scaler.transform(images_test)\n",
    "\n",
    "print(X_train_minmax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "VtV8pcOH_zVb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'degree': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "SVc prediction for inputs in 15701.155 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time \n",
    "\n",
    "#train the [-1,1]\n",
    "train_size=15000\n",
    "#parameters to check\n",
    "params_=[{\"C\": [1, 10, 100,1000],\"kernel\":['linear']},\n",
    "         {\"C\": [1, 10, 100,1000],\"gamma\": [0.01, 0.001,'scale','auto'],\"kernel\":['rbf', 'sigmoid']},\n",
    "         {\"C\": [1, 10, 100,1000],\n",
    "         \"degree\":[1,5,10],\n",
    "          \"gamma\": [0.01, 0.001,'scale','auto'],\n",
    "          \"kernel\":['poly']}\n",
    "        ]\n",
    "\n",
    "t0 = time.time()\n",
    "svc = GridSearchCV(SVC(),cv=5,param_grid=params_)  \n",
    "svc.fit(X_train_minmax[:train_size,:], np.array(labels_train)[:train_size])  \n",
    "print(svc.best_params_)  \n",
    "svc_predict = time.time() - t0\n",
    "#time that took to find the best parameter combination\n",
    "print(\"SVc prediction for inputs in %.3f s\"% (svc_predict))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5923\n",
      "           1       0.99      0.99      0.99      6742\n",
      "           2       0.97      0.98      0.98      5958\n",
      "           3       0.98      0.97      0.98      6131\n",
      "           4       0.98      0.98      0.98      5842\n",
      "           5       0.98      0.97      0.97      5421\n",
      "           6       0.99      0.99      0.99      5918\n",
      "           7       0.99      0.98      0.98      6265\n",
      "           8       0.96      0.98      0.97      5851\n",
      "           9       0.98      0.97      0.97      5949\n",
      "\n",
      "    accuracy                           0.98     60000\n",
      "   macro avg       0.98      0.98      0.98     60000\n",
      "weighted avg       0.98      0.98      0.98     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#make predictions on the test set for [-1,1]\n",
    "svc_predictions = svc.predict(X_train_minmax)\n",
    "print(classification_report(np.array(labels_train), svc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#code to pass all the results into a csv for [-1,1]\n",
    "lk=svc.cv_results_.keys()\n",
    "# print(lk)\n",
    "with open('minmax_results.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(lk)\n",
    "    row_counter=0\n",
    "    total_rows=len(list(svc.cv_results_.values())[0])\n",
    "    # print(len(list(svc.cv_results_.values())[0]))\n",
    "    for i in range(total_rows):\n",
    "      lv=[]\n",
    "      for v in svc.cv_results_.values():\n",
    "        lv.append(list(v)[i])\n",
    "      writer.writerow(lv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVc prediction for inputs in 27734.671 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time \n",
    "\n",
    "#Check for the best parameter conbination and train the [0,1]\n",
    "#the train size is 15k because it would take a lot of time to complete with more\n",
    "train_size=15000\n",
    "params_=[{\"C\": [1, 10, 100,1000],\"kernel\":['linear']},\n",
    "         {\"C\": [1, 10, 100,1000],\"gamma\": [0.01, 0.001,'scale','auto'],\"kernel\":['rbf', 'sigmoid']},\n",
    "         {\"C\": [1, 10, 100,1000],\n",
    "         \"degree\":[1,5,10],\n",
    "          \"gamma\": [0.01, 0.001,'scale','auto'],\n",
    "          \"kernel\":['poly']}\n",
    "        ]\n",
    "\n",
    "t0 = time.time()\n",
    "svc2 = GridSearchCV(SVC(),cv=5,param_grid=params_)  \n",
    "svc2.fit(X_train_maxabs[:train_size,:], np.array(labels_train)[:train_size])  \n",
    "print(svc2.best_params_)  \n",
    "svc_predict2 = time.time() - t0\n",
    "print(\"SVc prediction for inputs in %.3f s\"% (svc_predict2))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      5923\n",
      "           1       0.99      0.99      0.99      6742\n",
      "           2       0.97      0.98      0.97      5958\n",
      "           3       0.97      0.97      0.97      6131\n",
      "           4       0.97      0.98      0.98      5842\n",
      "           5       0.97      0.97      0.97      5421\n",
      "           6       0.99      0.99      0.99      5918\n",
      "           7       0.98      0.98      0.98      6265\n",
      "           8       0.97      0.97      0.97      5851\n",
      "           9       0.98      0.96      0.97      5949\n",
      "\n",
      "    accuracy                           0.98     60000\n",
      "   macro avg       0.98      0.98      0.98     60000\n",
      "weighted avg       0.98      0.98      0.98     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#make predictions on the test set for [0,1]\n",
    "svc_predictions2 = svc2.predict(X_train_maxabs)\n",
    "print(classification_report(np.array(labels_train), svc_predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#code to pass all the results into a csv for [0,1]\n",
    "lk=svc2.cv_results_.keys()\n",
    "# print(lk)\n",
    "with open('maxabs_results.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(lk)\n",
    "    row_counter=0\n",
    "    total_rows=len(list(svc2.cv_results_.values())[0])\n",
    "    # print(len(list(svc2.cv_results_.values())[0]))\n",
    "    for i in range(total_rows):\n",
    "      lv=[]\n",
    "      for v in svc2.cv_results_.values():\n",
    "        lv.append(list(v)[i])\n",
    "      writer.writerow(lv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for training:  316.7670681476593\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "#train with full data and best parameter combination [-1,1]\n",
    "#or replace the parameters with my first choice\n",
    "# C= 100, degree= 10, gamma= 0.001, kernel='poly'\n",
    "# C= 1, degree= 10, gamma= 'scale', kernel='poly'\n",
    "svc_minmax_fd=SVC(C= 1, degree= 10, gamma= 'scale', kernel='poly') \n",
    "svc_minmax_fd.fit(X_train_minmax, np.array(labels_train)) \n",
    "train_minmax=time.time()-t0\n",
    "print(\"Time for training: \",train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5923\n",
      "           1       1.00      1.00      1.00      6742\n",
      "           2       1.00      1.00      1.00      5958\n",
      "           3       1.00      1.00      1.00      6131\n",
      "           4       1.00      1.00      1.00      5842\n",
      "           5       1.00      1.00      1.00      5421\n",
      "           6       1.00      1.00      1.00      5918\n",
      "           7       1.00      1.00      1.00      6265\n",
      "           8       1.00      1.00      1.00      5851\n",
      "           9       1.00      1.00      1.00      5949\n",
      "\n",
      "    accuracy                           1.00     60000\n",
      "   macro avg       1.00      1.00      1.00     60000\n",
      "weighted avg       1.00      1.00      1.00     60000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.98      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.98      0.99      0.98       974\n",
      "           9       0.98      0.97      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#make predictions on the train set for [-1,1]\n",
    "svcfd_predictions_train= svc_minmax_fd.predict(X_train_minmax)\n",
    "print(classification_report(np.array(labels_train), svcfd_predictions_train))\n",
    "#make predictions on the test set for [-1,1]\n",
    "svcfd_predictions_test= svc_minmax_fd.predict(X_test_minmax)\n",
    "print(classification_report(np.array(labels_test), svcfd_predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for training:  232.6112630367279\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "#train with full data and best parameter combination [0,1]\n",
    "svc_maxabs_fd=SVC(C=100, gamma='scale', kernel='rbf')\n",
    "svc_maxabs_fd.fit(X_train_maxabs, np.array(labels_train)) \n",
    "train_maxabs=time.time()-t0\n",
    "print(\"Time for training: \",train_maxabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5923\n",
      "           1       1.00      1.00      1.00      6742\n",
      "           2       1.00      1.00      1.00      5958\n",
      "           3       1.00      1.00      1.00      6131\n",
      "           4       1.00      1.00      1.00      5842\n",
      "           5       1.00      1.00      1.00      5421\n",
      "           6       1.00      1.00      1.00      5918\n",
      "           7       1.00      1.00      1.00      6265\n",
      "           8       1.00      1.00      1.00      5851\n",
      "           9       1.00      1.00      1.00      5949\n",
      "\n",
      "    accuracy                           1.00     60000\n",
      "   macro avg       1.00      1.00      1.00     60000\n",
      "weighted avg       1.00      1.00      1.00     60000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.98      0.98      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.99      0.98      0.98       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.98      0.98      0.98       974\n",
      "           9       0.98      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#make predictions on the train set for [0,1]\n",
    "svcfd_predictions_train2= svc_maxabs_fd.predict(X_train_maxabs)\n",
    "print(classification_report(np.array(labels_train), svcfd_predictions_train2))\n",
    "#make predictions on the test set for [0,1]\n",
    "svcfd_predictions_test2= svc_maxabs_fd.predict(X_test_maxabs)\n",
    "print(classification_report(np.array(labels_test), svcfd_predictions_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More precision accuracy (60k Accuracy)!!\n",
      "\n",
      "Accuracy for minmax-train_set:  1.0\n",
      "Accuracy for minmax-test_set:  0.9864\n",
      "###########################################\n",
      "Accuracy for maxabs-train_set:  1.0\n",
      "Accuracy for maxabs-test_set:  0.9833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"More precision accuracy (60k Accuracy)!!\\n\")\n",
    "print(\"Accuracy for minmax-train_set: \",accuracy_score(np.array(labels_train),svcfd_predictions_train))\n",
    "print(\"Accuracy for minmax-test_set: \",accuracy_score(np.array(labels_test),svcfd_predictions_test))\n",
    "\n",
    "print(\"###########################################\")\n",
    "\n",
    "print(\"Accuracy for maxabs-train_set: \",accuracy_score(np.array(labels_train),svcfd_predictions_train2))\n",
    "print(\"Accuracy for maxabs-test_set: \",accuracy_score(np.array(labels_test),svcfd_predictions_test2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "PCA- 0.95\n",
      "(60000, 154)\n",
      "(10000, 154)\n",
      "Fit time for PCA 0.95 (maxabs):  97.0656213760376\n",
      "Accuracy for maxabs-train_set:  1.0\n",
      "Accuracy for maxabs-test_set:  0.9854\n",
      "_________________________________\n",
      "(60000, 154)\n",
      "(10000, 154)\n",
      "Done\n",
      "Fit time for PCA 0.95 (minmax):  884.3914382457733\n",
      "Accuracy for minmax-train_set:  0.82815\n",
      "Accuracy for minmax-test_set:  0.7133\n",
      "PCA- 0.8\n",
      "(60000, 44)\n",
      "(10000, 44)\n",
      "Fit time for PCA 0.8 (maxabs):  53.293978691101074\n",
      "Accuracy for maxabs-train_set:  1.0\n",
      "Accuracy for maxabs-test_set:  0.985\n",
      "_________________________________\n",
      "(60000, 44)\n",
      "(10000, 44)\n",
      "Done\n",
      "Fit time for PCA 0.8 (minmax):  374.6982681751251\n",
      "Accuracy for minmax-train_set:  0.8671833333333333\n",
      "Accuracy for minmax-test_set:  0.8303\n",
      "PCA- 0.6\n",
      "(60000, 17)\n",
      "(10000, 17)\n",
      "Fit time for PCA 0.6 (maxabs):  26.16868257522583\n",
      "Accuracy for maxabs-train_set:  0.9996333333333334\n",
      "Accuracy for maxabs-test_set:  0.9725\n",
      "_________________________________\n",
      "(60000, 17)\n",
      "(10000, 17)\n",
      "Done\n",
      "Fit time for PCA 0.6 (minmax):  114.75951743125916\n",
      "Accuracy for minmax-train_set:  0.8181833333333334\n",
      "Accuracy for minmax-test_set:  0.8059\n",
      "PCA- 0.5\n",
      "(60000, 11)\n",
      "(10000, 11)\n",
      "Fit time for PCA 0.5 (maxabs):  32.374810457229614\n",
      "Accuracy for maxabs-train_set:  0.9894833333333334\n",
      "Accuracy for maxabs-test_set:  0.9465\n",
      "_________________________________\n",
      "(60000, 11)\n",
      "(10000, 11)\n",
      "Done\n",
      "Fit time for PCA 0.5 (minmax):  100.97264647483826\n",
      "Accuracy for minmax-train_set:  0.78465\n",
      "Accuracy for minmax-test_set:  0.7726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# The percents of PCAs we want to check\n",
    "percs=[0.95,0.80,0.60,0.50]\n",
    "\n",
    "#Our best model for [0,1]\n",
    "svc_maxabs_fd=SVC(C=100, gamma='scale', kernel='rbf')\n",
    "#Our best model for [-1,1]\n",
    "svc_minmax_fd=SVC(C= 1, degree= 10, gamma= 'scale', kernel='poly')\n",
    "\n",
    "print(X_train_maxabs.shape)\n",
    "print(X_test_maxabs.shape)\n",
    "for p in percs:\n",
    "    print(\"PCA-\",p)\n",
    "    pca=PCA(p)\n",
    "    t0 = time.time()\n",
    "    train_maxabs=pca.fit_transform(X_train_maxabs)\n",
    "    test_maxabs=pca.transform(X_test_maxabs)\n",
    "    print(train_maxabs.shape)\n",
    "    print(test_maxabs.shape)\n",
    "    svc_maxabs_fd.fit(train_maxabs, np.array(labels_train)) \n",
    "    print(\"Fit time for PCA\",p,\"(maxabs): \",time.time()-t0)\n",
    "    \n",
    "    svcfd_predictions_train2= svc_maxabs_fd.predict(train_maxabs)\n",
    "    svcfd_predictions_test2= svc_maxabs_fd.predict(test_maxabs)\n",
    "    print(\"Accuracy for maxabs-train_set: \",accuracy_score(np.array(labels_train),svcfd_predictions_train2))\n",
    "    print(\"Accuracy for maxabs-test_set: \",accuracy_score(np.array(labels_test),svcfd_predictions_test2))\n",
    "    print(\"_________________________________\")\n",
    "    \n",
    "    pca2=PCA(p)\n",
    "    t0 = time.time()\n",
    "    train_minmax=pca2.fit_transform(X_train_minmax)\n",
    "    test_minmax=pca2.transform(X_test_minmax)\n",
    "    print(train_minmax.shape)\n",
    "    print(test_minmax.shape)\n",
    "    print(\"Done\")\n",
    "    svc_minmax_fd.fit(train_minmax, np.array(labels_train)) \n",
    "    print(\"Fit time for PCA\",p,\"(minmax): \",time.time()-t0)\n",
    "    svcfd_predictions_train= svc_minmax_fd.predict(train_minmax)\n",
    "    svcfd_predictions_test= svc_minmax_fd.predict(test_minmax)\n",
    "    print(\"Accuracy for minmax-train_set: \",accuracy_score(np.array(labels_train),svcfd_predictions_train))\n",
    "    print(\"Accuracy for minmax-test_set: \",accuracy_score(np.array(labels_test),svcfd_predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 5)\n",
      "(10000, 5)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "# some code for testing the models and see their behaviour based on the PCAs\n",
    "\n",
    "model=SVC(C= 100, degree= 10, gamma= 'scale', kernel='poly')\n",
    "pca2=PCA(0.3)\n",
    "\n",
    "t0 = time.time()\n",
    "train_minmax=pca2.fit_transform(X_train_minmax)\n",
    "test_minmax=pca2.transform(X_test_minmax)\n",
    "print(train_minmax.shape)\n",
    "print(test_minmax.shape)\n",
    "print(\"Done\")\n",
    "model.fit(train_minmax, np.array(labels_train)) \n",
    "print(\"Fit time for PCA\",0.3,\"(minmax): \",time.time()-t0)\n",
    "svcfd_predictions_train= model.predict(train_minmax)\n",
    "svcfd_predictions_test= model.predict(test_minmax)\n",
    "print(\"Accuracy for minmax-train_set: \",accuracy_score(np.array(labels_train),svcfd_predictions_train))\n",
    "print(\"Accuracy for minmax-test_set: \",accuracy_score(np.array(labels_test),svcfd_predictions_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MachineLearning3SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
